---
title: "Modelación"
author: "Jennifer Salazar"
date: "29/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Cargando la base de datos

```{r}
load("Base_modelar.RData")
```

# Modelos 

A continuacion se utilizaran diferentes modelos para despues escoger aquel que mejor se ajuste a las necesidades

## Se crea un nuevo dataframe con Num_hijos organizada

```{r}
barplot(prop.table(table(Base_modelar$Num_hijos)))
```

```{r}
(prop <- round(prop.table(table(Base_modelar$Num_hijos)), 6))
```

```{r}
sum(prop[6:15])
```

```{r}
Base_de_ensayo <- Base_modelar

Base_de_ensayo$Num_hijos[Base_de_ensayo$Num_hijos >= 5] <- 5
```

```{r}
table(Base_de_ensayo$Num_hijos)
```

```{r}
library(tidyverse)

# Variables en orden de importancia según RF
var_imprt <-  c(
    "Num_integrantes",
    "Estado_civil",
    "Genero",
    "Edad",
    "Vive_hogar_madre",
    "Num_hijos"
  )

# Se convierte la variable Num_hijos a factor

Base_modelar_f <- Base_de_ensayo[,var_imprt]
Base_modelar_f$Num_hijos <- as.factor(Base_modelar_f$Num_hijos) 

# Base_modelar_f <- Base_de_ensayo %>% 
#   select(all_of(var_imprt)) %>% 
#   mutate(
#     Num_hijos = factor(Num_hijos)
#   )

set.seed(15234) # Semilla

# Se saca una muestra de entrenamiento que conserve las proporciones en la varaible Num_hijos

trn_prop <- Base_modelar_f %>%
  mutate(
    var_indx = 1:dim(Base_modelar_f)[1]
  ) %>% 
  group_by(Num_hijos) %>% 
  sample_frac(0.8, replace = F)

# Se saca la muestra de test con las que no fueron seleccionadas en la muestra de train

tst_prop <- Base_modelar_f[-trn_prop$var_indx, ]


# Se elimina la variable de indice
trn_prop$var_indx <- NULL
```

```{r}
require(tidyverse)

Base_modelar_f %>% 
  count(Num_hijos)
```

Otra forma de seleccionar el conjunto de entrenamiento y de test

```{r}
# set.seed(65234)
# 
# porctj <- round(dim(Base_modelar)[1] * 0.8)
# 
# indx_train <- sample(1:dim(Base_modelar)[1], porctj)
# 
# train <- Base_modelar[indx_train, ]
# 
# test <- Base_modelar[-indx_train, ]
# 
# dim(test)[1] + dim(train)[1]
```


## Modelo de regresión lineal múltiple

```{r}
modelo1 <- lm(as.numeric(as.character(Num_hijos))~., data=trn_prop)
summary(modelo1)
```

```{r}
#plot(modelo1)
```

```{r}
# library(leaps)
# 
# mod_all <- regsubsets(Num_hijos~., data=Base_modelar, really.big=T)
# 
# plot(mod_all, scale = "adjr2")
# abline(v=33)
# 
# mod1 <- lm(Num_hijos~Genero+Num_integrantes+Estado_civil, data = Base_modelar)
# 
# summary(mod1)
# 
# mod1 <- lm(Num_hijos~Genero+Num_integrantes+Num_cuartos+Estado_civil+Ultimo_pago_energia+Contrato_vivienda, data = Base_modelar)
# 
# summary(mod1)
```


## Arbol de clasificación 

```{r}
require(rpart)
require(rpart.plot)
```

Ajustemos un arbol

```{r}
mod1_arboles <- rpart(Num_hijos~., data = trn_prop)
```

```{r}
# mod1_arboles
# 
# summary(mod1_arboles)
```

```{r}
#plot(mod1_arboles)
#text(mod1_arboles)
```

Gráfico mejorado:

```{r}
prp(mod1_arboles, type = 2, extra = 6, split.font = 3,    box.col = c(3:10)[mod1_arboles$frame$yval])
```

Hacemos las predicciones

```{r}
pred_mod1_arboles <-  predict(mod1_arboles, newdata = tst_prop, type = "class")
```

Matriz de confusión

```{r}
MC <- table(tst_prop$Num_hijos, pred_mod1_arboles)
MC
```
Calculamos el error

```{r}
acierto<-sum(diag(MC))/sum(MC)
paste("Tasa de acierto:", acierto)
error <- 1-acierto
paste("Tasa de error:", error)
```

## Prediccion modelo de regresión

```{r}
pred_mod1_reg <- predict(modelo1, newdata = tst_prop)
```

```{r}
pred_mod1_round <- round(pred_mod1_reg)
```

Matriz de confusión

```{r}
MC <- table(tst_prop$Num_hijos, pred_mod1_round)
MC
```

```{r}
acierto<-sum(diag(MC))/sum(MC)
paste("Tasa de acierto:", acierto)
error <- 1-acierto
paste("Tasa de error:", error)
```

## Arboles de regresion

```{r}
mod1_reg_arboles <- rpart(as.numeric(as.character(Num_hijos))~., data = trn_prop)
```

```{r}
# mod1_reg_arboles
# 
# summary(mod1_reg_arboles)
```

```{r}
prp(mod1_reg_arboles, type = 2, split.font = 3,    box.col = c(3:10)[mod1_reg_arboles$frame$yval])
```

Hacemos las predicciones

```{r}
pred_mod1_reg_arboles <-  predict(mod1_reg_arboles, newdata = tst_prop)
```

Matriz de confusión

```{r}
pred_mod1_reg_arboles <- round(pred_mod1_reg_arboles)
MC <- table(tst_prop$Num_hijos, pred_mod1_reg_arboles)
MC
```
Calculamos el error

```{r}
acierto<-sum(diag(MC))/sum(MC)
paste("Tasa de acierto:", acierto)
error <- 1-acierto
paste("Tasa de error:", error)
```

## Poisson

```{r}
require(gamlss)

HijosPoisson <-gamlss(as.numeric(as.character(Num_hijos))~., data= trn_prop, family=PO(mu.link="log"))
# Resumen del modelo
#summary(HijosPoisson)
```

```{r}
# Hacemos las predicciones

HijosPoisson <-  predict(HijosPoisson, newdata = tst_prop)
```

Matriz de confusión

```{r}
HijosPoisson <- round(HijosPoisson)

MC <- table(na.omit(tst_prop)$Num_hijos, HijosPoisson)
MC
```

Calculamos el error

```{r}
acierto<-sum(diag(MC))/sum(MC)
paste("Tasa de acierto:", acierto)
error <- 1-acierto
paste("Tasa de error:", error)
```


## Random Forest

```{r}
library(ISLR)
library(tree)
library(MASS)
library(randomForest)
library(gbm)
```

```{r, message=FALSE}
require(ranger)
```

```{r}
# Modelo RF
mod_RF <- ranger(
  Num_hijos~., 
  data = (trn_prop), 
  num.trees = 500, 
  mtry = 5, 
  max.depth = 8,
  importance = 'impurity'
)
```

```{r}
#sort(mod_RF$variable.importance, decreasing = T)
```

Se hacen las predicciones

```{r}
pred_mod_RF <- predict(mod_RF, data = (tst_prop))
```

Matriz de confusión

```{r}
MC <- table(predicho = pred_mod_RF$predictions, real = (tst_prop)$Num_hijos)
MC
```

Calculamos el error

```{r}
acierto<-sum(diag(MC))/sum(MC)
paste("Tasa de acierto:", acierto)
error <- 1-acierto
paste("Tasa de error:", error)
```

## Ensayo Random Forest y Boosting


```{r}
# set.seed(23)
# 
# forest <- randomForest(Num_hijos~., data = na.omit(trn_prop), mtry=5, tree=50, importance=TRUE)
# forest
# 
# pred_forest <- predict(forest, newdata = tst_prop)
```

```{r}
# library(gbm)
# set.seed(23)
# boost <- gbm(Num_hijos~., data = na.omit(trn_prop), n.trees = 50, interaction.depth = 4, shrinkage = 0.2, verbose = F, distribution = "laplace")
# 
# 
# pred_boost <- predict(boost, newdata = na.omit(tst_prop))
```

## Naive Bayes

```{r}
library(e1071)
library(caTools)
library(caret)
```

```{r}
# Setting Seed
mod_Naive_Bayes <- naiveBayes(Num_hijos ~ ., data = trn_prop)
# mod_Naive_Bayes
```

Se hacen las predicciones

```{r}
pred_bayes <- predict(mod_Naive_Bayes, newdata = tst_prop, type="class")
```

Matriz de confusión

```{r}
MC <- table(tst_prop$Num_hijos, pred_bayes)
MC
```

Calculamos el error

```{r}
acierto<-sum(diag(MC))/sum(MC)
paste("Tasa de acierto:", acierto)
error <- 1-acierto
paste("Tasa de error:", error)
```

## Knn

Conversion de las variables categoricas a variables dummy

```{r}
library(dummies)

# Conjunto de entrenamiento

Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
Base_KNN_dummy_trn <- cbind(Base_KNN_dummy_trn,"Num_hijos" = trn_prop$Num_hijos)
str(Base_KNN_dummy_trn)

# Conjunto de prueba

Base_KNN_dummy_tst <- dummy.data.frame(data=tst_prop[ ,-6])
Base_KNN_dummy_tst <- cbind(Base_KNN_dummy_tst,"Num_hijos" = tst_prop$Num_hijos)
str(Base_KNN_dummy_tst)
```



Normalización de Variables Numéricas

```{r}
#Conjunto de entrenamiento
datos_c_trn <- Base_KNN_dummy_trn
datos_c_trn[,c(1,10)] <- scale(datos_c_trn[,c(1,10)])

#Conjunto de prueba
datos_c_tst <- Base_KNN_dummy_tst
datos_c_tst[,c(1,10)] <- scale(datos_c_tst[,c(1,10)])

# Por último revisamos los valores normalizados de las variables que se encontrarán en todos los casos entre 0 y 1.

summary(datos_c_trn)
```



Conjuntos de entrenamiento y test

```{r}
train <- datos_c_trn[ ,-14] # crea train sin la variable respuesta
test <- datos_c_tst[ ,-14] # crea test sin la variable respuesta

y_train <- datos_c_trn[ ,14]
y_test <- datos_c_tst[ ,14]


summary(y_train)
```


```{r}
library(tidyverse)
library(class)
library(gmodels)
library(caret)
```


# Ajuste modelo Knn

```{r}
knn_model <- knn(train, test, cl = y_train, k = 18)
summary(knn_model)
```


```{r}
confusionMatrix(data = knn_model, reference = y_test)
```


```{r}
MC <- table(knn_model, y_test)
acierto <- sum(diag(MC))/sum(MC)
acierto

error <- 1- acierto
error

```


```{r}
library(kknn)
```


```{r}
modelo <- train.kknn(Num_hijos ~ ., data = datos_c_trn, kmax = 30)
modelo
```


```{r}
pred_knn <- predict(modelo, datos_c_tst)
summary(pred_knn)
```



```{r}
#pred_knn <- round(pred_knn)
MC <- table(pred_knn, datos_c_tst$Num_hijos)
acierto <- sum(diag(MC))/sum(MC)
acierto

error <- 1- acierto
error

```
