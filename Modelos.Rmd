---
title: "Modelación"
author: "Jennifer Salazar"
date: "29/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
load("Base_modelar.RData")
```


Modelo de regresión lineal múltiple


```{r}
modelo1 <- lm(Num_hijos~., data=Base_modelar)
summary(modelo1)
```



```{r}
plot(modelo1)
```


```{r}
Base_sin_na <- na.omit(Base_modelar)
```



```{r}
modelo1b <- lm(Num_hijos~., data=Base_sin_na)
summary(modelo1b)
```



```{r}
plot(modelo1b)
```



```{r}
library(leaps)
```

```{r}
mod_all <- regsubsets(Num_hijos~., data=Base_modelar, really.big=T)
```

```{r}
plot(mod_all, scale = "adjr2")
abline(v=33)
```

```{r}
mod1 <- lm(Num_hijos~Genero+Num_integrantes+Estado_civil, data = Base_modelar)

summary(mod1)
```

```{r}
mod1 <- lm(Num_hijos~Genero+Num_integrantes+Num_cuartos+Estado_civil+Ultimo_pago_energia+Contrato_vivienda, data = Base_modelar)

summary(mod1)
```


# Arbol de clasificacion 

```{r}
require(rpart)
require(rpart.plot)
```


```{r}

# Se saca una muestra de entrenamiento que conserve las proporciones en la varaible Num_hijos

library(tidyverse)

trn_prop <- Base_modelar %>%
  mutate(
    var_indx = 1:dim(Base_modelar)[1]
  ) %>% 
  group_by(Num_hijos) %>% 
  sample_frac(0.8, replace = F)

# Se saca la muestra de test con las que no fueron seleccionadas en la muestra de train

tst_prop <- Base_modelar[-trn_prop$var_indx, ]


# Se elimina la variable de indice
trn_prop$var_indx <- NULL
```

```{r}
# set.seed(65234)
# 
# porctj <- round(dim(Base_modelar)[1] * 0.8)
# 
# indx_train <- sample(1:dim(Base_modelar)[1], porctj)
# 
# train <- Base_modelar[indx_train, ]
# 
# test <- Base_modelar[-indx_train, ]
# 
# dim(test)[1] + dim(train)[1]
```

```{r}
# ajustemos un arbol

mod1_arboles <- rpart(factor(Num_hijos)~., data = trn_prop)
```

```{r}
# mod1_arboles
# 
# summary(mod1_arboles)
```

```{r}
plot(mod1_arboles)
text(mod1_arboles)
```

Gráfico mejorado:

```{r}
prp(mod1_arboles, type = 2, extra = 6, split.font = 3,    box.col = c(3:10)[mod1_arboles$frame$yval])
```

```{r}
# Hacemos las predicciones

pred_mod1_arboles <-  predict(mod1_arboles, newdata = tst_prop, type = "class")
```

```{r}
# Matriz de confusión

MC <- table(tst_prop$Num_hijos, pred_mod1_arboles)
MC
# calculamos el error
acierto<-sum(diag(MC))/sum(MC)
acierto
error <- 1-acierto
error
```

```{r}
require(tidyverse)

Base_modelar %>% 
  count(Num_hijos)
```


```{r}
# require(caret)
# require(e1071)
# 
# b <- varImp(mod1_arboles) 
# 
# i <- b %>% 
#   order()
# 
# cbind(row.names(b)[i], sort(b$Overall, decreasing = F))

```



# Errores modelo regresión

```{r}
mod1_reg <- lm(Num_hijos~Genero+Num_integrantes+Estado_civil, data = trn_prop, na.action = na.omit)

summary(mod1_reg)
```


```{r}
pred_mod1_reg <- predict(mod1_reg, newdata = tst_prop)
```

```{r}
MSE <- mean((tst_prop$Num_hijos - pred_mod1_reg)^2)
```

```{r}
MSE
```
## Error relativo porcentual

```{r}
pred_mod1_round <- round(pred_mod1_reg)
```

```{r}
# Matriz de confusión

MC <- table(tst_prop$Num_hijos, pred_mod1_round)
MC
# calculamos el error
acierto<-sum(diag(MC))/sum(MC)
acierto
error <- 1-acierto
error
```

# Arboles de regresion

```{r}
mod1_reg_arboles <- rpart(Num_hijos~., data = trn_prop, na.action = na.omit)
```

```{r}
# mod1_reg_arboles
# 
# summary(mod1_reg_arboles)
```

```{r}
prp(mod1_reg_arboles, type = 2, split.font = 3,    box.col = c(3:10)[mod1_reg_arboles$frame$yval])
```

```{r}
# Hacemos las predicciones

pred_mod1_reg_arboles <-  predict(mod1_reg_arboles, newdata = tst_prop)
```

```{r}
# Matriz de confusión

pred_mod1_reg_arboles <- round(pred_mod1_reg_arboles)

MC <- table(tst_prop$Num_hijos, pred_mod1_reg_arboles)
MC
# calculamos el error
acierto<-sum(diag(MC))/sum(MC)
acierto
error <- 1-acierto
error
```

# Poisson

```{r}
require(gamlss)
HijosPoisson <-gamlss(Num_hijos~., data= na.omit(trn_prop), family=PO(mu.link="log"))
# Resumen del modelo
summary(HijosPoisson)
```

```{r}
# Hacemos las predicciones

HijosPoisson <-  predict(HijosPoisson, newdata = na.omit(tst_prop))
```

```{r}
# Matriz de confusión

HijosPoisson <- round(HijosPoisson)

MC <- table(na.omit(tst_prop)$Num_hijos, HijosPoisson)
MC
# calculamos el error
acierto<-sum(diag(MC))/sum(MC)
acierto
error <- 1-acierto
error
```


# Más arboles





```{r}
library(ISLR)
library(tree)
library(MASS)
library(randomForest)
library(gbm)
```


# Bosque aleatorio (Random Forest)


```{r}
# set.seed(23)
# 
# forest <- randomForest(Num_hijos~., data = na.omit(trn_prop), mtry=5, tree=50, importance=TRUE)
# forest
# 
# pred_forest <- predict(forest, newdata = tst_prop)
```




```{r}
# library(gbm)
# set.seed(23)
# boost <- gbm(Num_hijos~., data = na.omit(trn_prop), n.trees = 50, interaction.depth = 4, shrinkage = 0.2, verbose = F, distribution = "laplace")
# 
# 
# pred_boost <- predict(boost, newdata = na.omit(tst_prop))
```







```{r}
# pred_boost <- round(pred_boost)
# MC <- table(na.omit(tst_prop)$Num_hijos, pred_boost)
# MC
# # calculamos el error
# acierto<-sum(diag(MC))/sum(MC)
# acierto
# error <- 1-acierto
# error
```






