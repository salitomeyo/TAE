tst_prop <- tst_prop[sample(1:dim(tst_prop)[1]), ]
paste("Semilla:", i)
## Arbol de clasificación
arbol_clasificacion <- rpart(Num_hijos~., data = trn_prop)
pred_arbol_clasificacion <-  predict(arbol_clasificacion, newdata = tst_prop, type=
"class")
tasa_arbol_clasificacion <- matriz_confusion(pred_arbol_clasificacion,
tst_prop$Num_hijos)
paste("Tasa acierto arbol clasificacion:", tasa_arbol_clasificacion)
# Modelo RF
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF, tst_prop$Num_hijos)
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF, tst_prop$Num_hijos)
pred_RF
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
paste("Tasa acierto Ramdon Forest:", tasa_RF)
Naive_Bayes <- naiveBayes(Num_hijos ~ ., data = trn_prop)
pred_Naive_Bayes <- predict(Naive_Bayes, newdata = tst_prop, type="class")
pred_Naive_Bayes <- predict(Naive_Bayes, newdata = tst_prop, type="class")
tasa_Naive_Bayes <- matriz_confusion(pred_Naive_Bayes, tst_prop$Num_hijos)
paste("Tasa acierto Naive Bayes:", tasa_Naive_Bayes)
## Knn
# Conjunto de entrenamiento
Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
## Knn
# Conjunto de entrenamiento
Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
Base_KNN_dummy_trn <- cbind(Base_KNN_dummy_trn,"Num_hijos" = trn_prop$Num_hijos)
# Conjunto de prueba
Base_KNN_dummy_tst <- dummy.data.frame(data=tst_prop[ ,-6])
Base_KNN_dummy_tst <- cbind(Base_KNN_dummy_tst,"Num_hijos" = tst_prop$Num_hijos)
#Conjunto de entrenamiento
datos_c_trn <- Base_KNN_dummy_trn
datos_c_trn[,c(1,10)] <- scale(datos_c_trn[,c(1,10)])
#Conjunto de prueba
datos_c_tst <- Base_KNN_dummy_tst
datos_c_tst[,c(1,10)] <- scale(datos_c_tst[,c(1,10)])
# Separación de la variable respuesta
train <- datos_c_trn[ ,-14] # crea train sin la variable respuesta
test <- datos_c_tst[ ,-14] # crea test sin la variable respuesta
y_train <- datos_c_trn[ ,14]
y_test <- datos_c_tst[ ,14]
pred_knn <- knn(train, test, cl = y_train, k = 20)
tasa_knn <- matriz_confusion(pred_knn, y_test)
paste("Tasa acierto arbol clasificacion:", tasa_knn)
tasas <- c(tasa_arbol_clasificacion, tasa_RF, tasa_Naive_Bayes, tasa_knn)
df[i,] <- tasas
for(i in 1:20){
set.seed(i) # Semilla
# Se saca una muestra de entrenamiento que conserve las proporciones en la varaible Num_hijos
trn_prop <- Base_modelar_f %>%
mutate(
var_indx = 1:dim(Base_modelar_f)[1]
) %>%
group_by(Num_hijos) %>%
sample_frac(0.8, replace = F)
# Se saca la muestra de test con las que no fueron seleccionadas en la muestra de
# train
tst_prop <- Base_modelar_f[-trn_prop$var_indx, ]
# Se elimina la variable de indice
trn_prop$var_indx <- NULL
trn_prop <- trn_prop[sample(1:dim(trn_prop)[1]), ]
tst_prop <- tst_prop[sample(1:dim(tst_prop)[1]), ]
paste("Semilla:", i)
# Ajuste de los modelos
## Arbol de clasificación
arbol_clasificacion <- rpart(Num_hijos~., data = trn_prop)
pred_arbol_clasificacion <-  predict(arbol_clasificacion, newdata = tst_prop, type=
"class")
tasa_arbol_clasificacion <- matriz_confusion(pred_arbol_clasificacion,
tst_prop$Num_hijos)
paste("Tasa acierto arbol clasificacion:", tasa_arbol_clasificacion)
# Modelo RF
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
paste("Tasa acierto Ramdon Forest:", tasa_RF)
## Naive Bayes
Naive_Bayes <- naiveBayes(Num_hijos ~ ., data = trn_prop)
pred_Naive_Bayes <- predict(Naive_Bayes, newdata = tst_prop, type="class")
tasa_Naive_Bayes <- matriz_confusion(pred_Naive_Bayes, tst_prop$Num_hijos)
paste("Tasa acierto Naive Bayes:", tasa_Naive_Bayes)
## Knn
# Conjunto de entrenamiento
Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
Base_KNN_dummy_trn <- cbind(Base_KNN_dummy_trn,"Num_hijos" = trn_prop$Num_hijos)
# Conjunto de prueba
Base_KNN_dummy_tst <- dummy.data.frame(data=tst_prop[ ,-6])
Base_KNN_dummy_tst <- cbind(Base_KNN_dummy_tst,"Num_hijos" = tst_prop$Num_hijos)
#Conjunto de entrenamiento
datos_c_trn <- Base_KNN_dummy_trn
datos_c_trn[,c(1,10)] <- scale(datos_c_trn[,c(1,10)])
#Conjunto de prueba
datos_c_tst <- Base_KNN_dummy_tst
datos_c_tst[,c(1,10)] <- scale(datos_c_tst[,c(1,10)])
# Separación de la variable respuesta
train <- datos_c_trn[ ,-14] # crea train sin la variable respuesta
test <- datos_c_tst[ ,-14] # crea test sin la variable respuesta
y_train <- datos_c_trn[ ,14]
y_test <- datos_c_tst[ ,14]
pred_knn <- knn(train, test, cl = y_train, k = 20)
tasa_knn <- matriz_confusion(pred_knn, y_test)
paste("Tasa acierto arbol clasificacion:", tasa_knn)
tasas <- c(tasa_arbol_clasificacion, tasa_RF, tasa_Naive_Bayes, tasa_knn)
df[i,] <- tasas
}
for(i in 1:20){
set.seed(i) # Semilla
# Se saca una muestra de entrenamiento que conserve las proporciones en la varaible Num_hijos
trn_prop <- Base_modelar_f %>%
mutate(
var_indx = 1:dim(Base_modelar_f)[1]
) %>%
group_by(Num_hijos) %>%
sample_frac(0.8, replace = F)
# Se saca la muestra de test con las que no fueron seleccionadas en la muestra de
# train
tst_prop <- Base_modelar_f[-trn_prop$var_indx, ]
# Se elimina la variable de indice
trn_prop$var_indx <- NULL
trn_prop <- trn_prop[sample(1:dim(trn_prop)[1]), ]
tst_prop <- tst_prop[sample(1:dim(tst_prop)[1]), ]
print(paste("Semilla:", i))
# Ajuste de los modelos
## Arbol de clasificación
arbol_clasificacion <- rpart(Num_hijos~., data = trn_prop)
pred_arbol_clasificacion <-  predict(arbol_clasificacion, newdata = tst_prop, type=
"class")
tasa_arbol_clasificacion <- matriz_confusion(pred_arbol_clasificacion,
tst_prop$Num_hijos)
print(paste("Tasa acierto arbol clasificacion:", tasa_arbol_clasificacion))
# Modelo RF
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
print(paste("Tasa acierto Ramdon Forest:", tasa_RF))
## Naive Bayes
Naive_Bayes <- naiveBayes(Num_hijos ~ ., data = trn_prop)
pred_Naive_Bayes <- predict(Naive_Bayes, newdata = tst_prop, type="class")
tasa_Naive_Bayes <- matriz_confusion(pred_Naive_Bayes, tst_prop$Num_hijos)
print(paste("Tasa acierto Naive Bayes:", tasa_Naive_Bayes))
## Knn
# Conjunto de entrenamiento
Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
Base_KNN_dummy_trn <- cbind(Base_KNN_dummy_trn,"Num_hijos" = trn_prop$Num_hijos)
# Conjunto de prueba
Base_KNN_dummy_tst <- dummy.data.frame(data=tst_prop[ ,-6])
Base_KNN_dummy_tst <- cbind(Base_KNN_dummy_tst,"Num_hijos" = tst_prop$Num_hijos)
#Conjunto de entrenamiento
datos_c_trn <- Base_KNN_dummy_trn
datos_c_trn[,c(1,10)] <- scale(datos_c_trn[,c(1,10)])
#Conjunto de prueba
datos_c_tst <- Base_KNN_dummy_tst
datos_c_tst[,c(1,10)] <- scale(datos_c_tst[,c(1,10)])
# Separación de la variable respuesta
train <- datos_c_trn[ ,-14] # crea train sin la variable respuesta
test <- datos_c_tst[ ,-14] # crea test sin la variable respuesta
y_train <- datos_c_trn[ ,14]
y_test <- datos_c_tst[ ,14]
pred_knn <- knn(train, test, cl = y_train, k = 20)
tasa_knn <- matriz_confusion(pred_knn, y_test)
print(paste("Tasa acierto arbol clasificacion:", tasa_knn))
tasas <- c(tasa_arbol_clasificacion, tasa_RF, tasa_Naive_Bayes, tasa_knn)
df[i,] <- tasas
}
for(i in 1:20){
set.seed(i) # Semilla
# Se saca una muestra de entrenamiento que conserve las proporciones en la varaible Num_hijos
trn_prop <- Base_modelar_f %>%
mutate(
var_indx = 1:dim(Base_modelar_f)[1]
) %>%
group_by(Num_hijos) %>%
sample_frac(0.8, replace = F)
# Se saca la muestra de test con las que no fueron seleccionadas en la muestra de
# train
tst_prop <- Base_modelar_f[-trn_prop$var_indx, ]
# Se elimina la variable de indice
trn_prop$var_indx <- NULL
trn_prop <- trn_prop[sample(1:dim(trn_prop)[1]), ]
tst_prop <- tst_prop[sample(1:dim(tst_prop)[1]), ]
print(paste("Semilla:", i))
# Ajuste de los modelos
## Arbol de clasificación
arbol_clasificacion <- rpart(Num_hijos~., data = trn_prop)
pred_arbol_clasificacion <-  predict(arbol_clasificacion, newdata = tst_prop, type=
"class")
tasa_arbol_clasificacion <- matriz_confusion(pred_arbol_clasificacion,
tst_prop$Num_hijos)
print(paste("Tasa acierto arbol clasificacion:", tasa_arbol_clasificacion))
# Modelo RF
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
print(paste("Tasa acierto Ramdon Forest:", tasa_RF))
## Naive Bayes
Naive_Bayes <- naiveBayes(Num_hijos ~ ., data = trn_prop)
pred_Naive_Bayes <- predict(Naive_Bayes, newdata = tst_prop, type="class")
tasa_Naive_Bayes <- matriz_confusion(pred_Naive_Bayes, tst_prop$Num_hijos)
print(paste("Tasa acierto Naive Bayes:", tasa_Naive_Bayes))
## Knn
# Conjunto de entrenamiento
Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
Base_KNN_dummy_trn <- cbind(Base_KNN_dummy_trn,"Num_hijos" = trn_prop$Num_hijos)
# Conjunto de prueba
Base_KNN_dummy_tst <- dummy.data.frame(data=tst_prop[ ,-6])
Base_KNN_dummy_tst <- cbind(Base_KNN_dummy_tst,"Num_hijos" = tst_prop$Num_hijos)
#Conjunto de entrenamiento
datos_c_trn <- Base_KNN_dummy_trn
datos_c_trn[,c(1,10)] <- scale(datos_c_trn[,c(1,10)])
#Conjunto de prueba
datos_c_tst <- Base_KNN_dummy_tst
datos_c_tst[,c(1,10)] <- scale(datos_c_tst[,c(1,10)])
# Separación de la variable respuesta
train <- datos_c_trn[ ,-14] # crea train sin la variable respuesta
test <- datos_c_tst[ ,-14] # crea test sin la variable respuesta
y_train <- datos_c_trn[ ,14]
y_test <- datos_c_tst[ ,14]
pred_knn <- knn(train, test, cl = y_train, k = 20)
tasa_knn <- matriz_confusion(pred_knn, y_test)
print(paste("Tasa acierto Knn:", tasa_knn))
tasas <- c(tasa_arbol_clasificacion, tasa_RF, tasa_Naive_Bayes, tasa_knn)
df[i,] <- tasas
}
colMeans(df)
round(colMeans(df),4)
round(colMeans(df),2)
round(colMeans(df),3)
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
print(paste("Tasa acierto Ramdon Forest:", tasa_RF))
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 500,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
print(paste("Tasa acierto Ramdon Forest:", tasa_RF))
RF <- ranger(Num_hijos~.,  data = (trn_prop),   num.trees = 50,  mtry = 5,
max.depth = 8,  importance = 'impurity')
pred_RF <- predict(RF, data = (tst_prop))
tasa_RF <- matriz_confusion(pred_RF$predictions, tst_prop$Num_hijos)
print(paste("Tasa acierto Ramdon Forest:", tasa_RF))
#Librerias
require(ranger)
require(tidyverse)
# Cargando la base de datos
load("Base_modelar.RData")
Base_modelo <- Base_modelar
Base_modelo$Num_hijos[Base_de_ensayo$Num_hijos >= 5] <- 5
# Variable finales
var_imprt <-  c(
"Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre",
"Num_hijos"
)
# Se seleccionan solo las variables importantes
# Variable respuesta se convierte a factor
Base_modelo <-Base_modelo[,var_imprt]
Base_modelo$Num_hijos <- as.factor(Base_modelo_f$Num_hijos)
View(Base_modelo)
RandomForest <- ranger(Num_hijos~.,  data = Base_modelo,   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
save(RandomForest, file="RandomForest.Rdata")
saveRDS(RandomForest, "modeloRF.rds")
var_imprt
df <- data.frame(Miguel, Jennifer, Juan, Cristina)
Miguel <- c(3, 6, 1, 52, 2)
Jennifer <- c(4, 2, 2, 43, 3)
Juan <- c(4, 6, 1, 59, 2)
Cristina <- c(3, 2, 2, 50, 2)
df <- data.frame(Miguel, Jennifer, Juan, Cristina)
View(df)
df <- rbind(Miguel, Jennifer, Juan, Cristina)
colnames(df) <- c("Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre")
colnames(df) <- c("Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre")
df <- data.frame(df)
colnames(df) <- c("Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre")
Miguel <- c(3, 6, 1, 52, 2)
Jennifer <- c(4, 2, 2, 43, 3)
Juan <- c(4, 6, 1, 59, 2)
Cristina <- c(3, 2, 2, 50, 2)
df <- rbind(Miguel, Jennifer, Juan, Cristina)
df <- data.frame(df)
colnames(df) <- c("Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre")
load("RandomForest.Rdata")
predict(RandomForest, df)
prediccion <- predict(RandomForest, df)
prediccion$predictions
#Librerias
require(ranger)
require(tidyverse)
#Librerias
require(ranger)
require(tidyverse)
# Cargando la base de datos
load("Base_modelar.RData")
Base_modelo <- Base_modelar
Base_modelo$Num_hijos[Base_modelo$Num_hijos >= 5] <- 5
# Variable finales
var_imprt <-  c(
"Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre",
"Num_hijos"
)
# Se seleccionan solo las variables importantes
# Variable respuesta se convierte a factor
Base_modelo <-Base_modelo[,var_imprt]
Base_modelo$Num_hijos <- as.factor(Base_modelo$Num_hijos)
RandomForest <- ranger(Num_hijos~.,  data = Base_modelo,   num.trees = 100,  mtry = 5,
max.depth = 8,  importance = 'impurity')
save(RandomForest, file="RandomForest.Rdata")
saveRDS(RandomForest, "modeloRF.rds")
Miguel <- c(3, 6, 1, 52, 2)
Jennifer <- c(4, 2, 2, 43, 3)
Juan <- c(4, 6, 1, 59, 2)
Cristina <- c(3, 2, 2, 50, 2)
df <- rbind(Miguel, Jennifer, Juan, Cristina)
df <- data.frame(df)
colnames(df) <- c("Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre")
load("RandomForest.Rdata")
prediccion <- predict(RandomForest, df)
prediccion$predictions
modeloRF=readRDS("modeloRF.rds")
prediccion2 <- predict(modeloRF, df)
prediccion2$predictions
setwd("D:/Descargas")
getwd()
knitr::opts_chunk$set(echo = TRUE)
library(readr)
datos_ejercicio1 <- read_csv("datos_ejercicio1.txt")
datos_ejercicio1 <- read_csv("datos_ejercicio1.txt")
library(readr)
datos_ejercicio1 <- read_csv("datos_ejercicio1.txt")
datos_ejercicio1 <- read_csv("datos_ejercicio1.txt", header=T)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", header=T)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", header=T)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", header=T,sep=",")
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", header=T)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", header=T)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt")
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".")
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", sep=",")
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", sep=",",, header = TRUE)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", sep=",",, header = TRUE)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", sep=",",, header = TRUE)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", sep=",",, header = TRUE)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", sep=",",, header = TRUE)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".",, header = TRUE)
View(datos_ejercicio1)
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", header = TRUE)
View(datos_ejercicio1)
barplot(datos)
barplot(datos_ejercicio1)
barplot(datos_ejercicio1$Datos)
View(datos_ejercicio1)
hist(datos_ejercicio1)
hist(datos_ejercicio1$Datos)
summary(datos_ejercicio1$Datos)
datos_ejercicio1$Datos <- as.factor(datos_ejercicio1$Datos)
summary(datos_ejercicio1$Datos)
barplot(datos_ejercicio1$Datos)
barplot(datos_ejercicio1$Datos)
barplot(table(datos_ejercicio1$Datos))
hist(datos_ejercicio1$Datos, breaks = "Sturgues")
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", header = TRUE)
hist(datos_ejercicio1$Datos, breaks = "Sturgues")
hist(datos_ejercicio1$Datos, breaks = "Sturgues")
hist(datos_ejercicio1$Datos, breaks = "Sturges")
hist(datos_ejercicio1$Datos, breaks = 10)
hist(datos_ejercicio1$Datos, breaks = 20)
hist(datos_ejercicio1$Datos, breaks = 5)
hist(datos_ejercicio1$Datos)
summary(datos_ejercicio1$Datos)
datos_ejercicio1$Datos <- as.factor(datos_ejercicio1$Datos)
summary(datos_ejercicio1$Datos)
barplot(table(datos_ejercicio1$Datos))
datos_ejercicio1 <- read.table("datos_ejercicio1.txt", dec=".", header = TRUE)
mean(datos_ejercicio1$Datos)
median(datos_ejercicio1$Datos)
max(table(datos_ejercicio1$Datos))
table(datos_ejercicio1$Datos)
plot(datos_ejercicio1$Datos)
plot(datos_ejercicio1$Datos, type="l")
barplot(table(datos_ejercicio1$Datos))
barplot(table(datos_ejercicio1$Datos), col="cyan4")
barplot(table(datos_ejercicio1$Datos), col="cyan4", ylab="Frecuencias", xlab="Costos de materia prima en millones", main="Tabla de frecuencias")
barplot(table(datos_ejercicio1$Datos), col="cyan4", ylab="Frecuencias", xlab="Costos de materia prima en millones", main="Tabla de frecuencias")
grid()
barplot(table(datos_ejercicio1$Datos), col="cyan4", ylab="Frecuencias", xlab="Costos de materia prima en millones", main="Tabla de frecuencias")
grid()
barplot(table(datos_ejercicio1$Datos), col="cyan4", ylab="Frecuencias", xlab="Costos de materia prima en millones", main="Tabla de frecuencias")
barplot(table(datos_ejercicio1$Datos), col="cyan4", ylab="Frecuencias", xlab="Costos de materia prima en millones", main="Tabla de frecuencias")
grid()
setwd("~/GitHub/TAE")
load("Base_modelar.RData")
require(rpart)
require(rpart.plot)
library(ISLR)
library(tree)
library(MASS)
library(randomForest)
library(gbm)
require(ranger)
library(e1071)
library(caTools)
library(caret)
library(tidyverse)
library(class)
library(gmodels)
library(dummies)
load("Base_modelar.RData")
Muchos_hijos <- Base_modelar[Base_modelar$Num_hijos >= 5,]
View(Muchos_hijos)
library(tidyverse)
# Variables en orden de importancia según RF
var_imprt <-  c(
"Num_integrantes",
"Estado_civil",
"Genero",
"Edad",
"Vive_hogar_madre",
"Num_hijos"
)
Muchos_hijos <- Muchos_hijos[,var_imprt]
View(Muchos_hijos)
str(Muchos_hijos)
Muchos_hijos$Num_hijos <- as.factor(Muchos_hijos)
Muchos_hijos$Num_hijos <- as.factor(Muchos_hijos$Num_hijos)
matriz_confusion <- function(prediccion, reales){
MC <- table(prediccion, reales)
acierto <- sum(diag(MC))/sum(MC)
return(acierto)
}
set.seed(23) # Semilla
# Se saca una muestra de entrenamiento que conserve las proporciones en la varaible Num_hijos
trn_prop <- Muchos_hijos %>%
mutate(
var_indx = 1:dim(Muchos_hijos)[1]
) %>%
group_by(Num_hijos) %>%
sample_frac(0.8, replace = F)
# Se saca la muestra de test con las que no fueron seleccionadas en la muestra de
# train
tst_prop <- Muchos_hijos[-trn_prop$var_indx, ]
# Se elimina la variable de indice
trn_prop$var_indx <- NULL
trn_prop <- trn_prop[sample(1:dim(trn_prop)[1]), ]
tst_prop <- tst_prop[sample(1:dim(tst_prop)[1]), ]
## Knn
# Conjunto de entrenamiento
Base_KNN_dummy_trn <- dummy.data.frame(data=data.frame(trn_prop[ ,-6]))
Base_KNN_dummy_trn <- cbind(Base_KNN_dummy_trn,"Num_hijos" = trn_prop$Num_hijos)
# Conjunto de prueba
Base_KNN_dummy_tst <- dummy.data.frame(data=tst_prop[ ,-6])
Base_KNN_dummy_tst <- cbind(Base_KNN_dummy_tst,"Num_hijos" = tst_prop$Num_hijos)
#Conjunto de entrenamiento
datos_c_trn <- Base_KNN_dummy_trn
datos_c_trn[,c(1,10)] <- scale(datos_c_trn[,c(1,10)])
#Conjunto de prueba
datos_c_tst <- Base_KNN_dummy_tst
datos_c_tst[,c(1,10)] <- scale(datos_c_tst[,c(1,10)])
# Separación de la variable respuesta
train <- datos_c_trn[ ,-14] # crea train sin la variable respuesta
test <- datos_c_tst[ ,-14] # crea test sin la variable respuesta
y_train <- datos_c_trn[ ,14]
y_test <- datos_c_tst[ ,14]
pred_knn <- knn(train, test, cl = y_train, k = 20)
tasa_knn <- matriz_confusion(pred_knn, y_test)
print(paste("Tasa acierto Knn:", tasa_knn))
MC <- table(pred_knn, y_test)
MC
